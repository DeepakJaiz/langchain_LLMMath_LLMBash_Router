{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c303b2",
   "metadata": {},
   "source": [
    "## LLM Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2fc17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'openai api key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e06ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "What is 13 raised to the .3432 power?\u001b[32;1m\u001b[1;3m\n",
      "```text\n",
      "13 ** .3432\n",
      "```\n",
      "...numexpr.evaluate(\"13 ** .3432\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m2.4116004626599237\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: 2.4116004626599237'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, LLMMathChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "llm_math = LLMMathChain.from_llm(llm, verbose=True)\n",
    "\n",
    "llm_math.run(\"What is 13 raised to the .3432 power?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36bfff5",
   "metadata": {},
   "source": [
    "## LLM Bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a91efea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMBashChain chain...\u001b[0m\n",
      "Please write a bash script that prints 'Hello World' to the console.\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "```bash\n",
      "echo \"Hello World\"\n",
      "```\u001b[0m\n",
      "Code: \u001b[33;1m\u001b[1;3m['echo \"Hello World\"']\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m\"Hello World\"\n",
      "\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Hello World\"\\r\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMBashChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "text = \"Please write a bash script that prints 'Hello World' to the console.\"\n",
    "\n",
    "bash_chain = LLMBashChain.from_llm(llm, verbose=True)\n",
    "\n",
    "bash_chain.run(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3c28e7",
   "metadata": {},
   "source": [
    "### Customize Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8141d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.llm_bash.prompt import BashOutputParser\n",
    "\n",
    "_PROMPT_TEMPLATE = \"\"\"If someone asks you to perform a task, your job is to come up with a series of bash commands that will perform the task. There is no need to put \"#!/bin/bash\" in your answer. Make sure to reason step by step, using this format:\n",
    "Question: \"copy the files in the directory named 'target' into a new directory at the same level as target called 'myNewDirectory'\"\n",
    "I need to take the following actions:\n",
    "- List all files in the directory\n",
    "- Create a new directory\n",
    "- Copy the files from the first directory into the second directory\n",
    "```bash\n",
    "ls\n",
    "mkdir myNewDirectory\n",
    "cp -r target/* myNewDirectory\n",
    "```\n",
    "\n",
    "Do not use 'echo' when writing the script.\n",
    "\n",
    "That is the format. Begin!\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(input_variables=[\"question\"], template=_PROMPT_TEMPLATE, output_parser=BashOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53ae8220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMBashChain chain...\u001b[0m\n",
      "Please write a bash script that prints 'Hello World' to the console.\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "```bash\n",
      "printf \"Hello World\\n\"\n",
      "```\u001b[0m\n",
      "Code: \u001b[33;1m\u001b[1;3m['printf \"Hello World\\\\n\"']\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3mCommand 'printf \"Hello World\\n\"' returned non-zero exit status 1.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Command \\'printf \"Hello World\\\\n\"\\' returned non-zero exit status 1.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bash_chain = LLMBashChain.from_llm(llm, prompt=PROMPT, verbose=True)\n",
    "\n",
    "text = \"Please write a bash script that prints 'Hello World' to the console.\"\n",
    "\n",
    "bash_chain.run(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee628ee3",
   "metadata": {},
   "source": [
    "### Persistent Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f14315",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Persistent bash processes are not yet supported on Windows.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BashProcess\n\u001b[1;32m----> 4\u001b[0m persistent_process \u001b[38;5;241m=\u001b[39m \u001b[43mBashProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersistent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m bash_chain \u001b[38;5;241m=\u001b[39m LLMBashChain\u001b[38;5;241m.\u001b[39mfrom_llm(llm, bash_process\u001b[38;5;241m=\u001b[39mpersistent_process, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList the current directory then move up a level.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\utilities\\bash.py:45\u001b[0m, in \u001b[0;36mBashProcess.__init__\u001b[1;34m(self, strip_newlines, return_err_output, persistent)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m persistent:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid4())\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_persistent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\utilities\\bash.py:51\u001b[0m, in \u001b[0;36mBashProcess._initialize_persistent_process\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_persistent_process\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pexpect\u001b[38;5;241m.\u001b[39mspawn:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# Start bash in a clean environment\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# Doesn't work on windows\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     pexpect \u001b[38;5;241m=\u001b[39m \u001b[43m_lazy_import_pexpect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     process \u001b[38;5;241m=\u001b[39m pexpect\u001b[38;5;241m.\u001b[39mspawn(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-i\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--norc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--noprofile\u001b[39m\u001b[38;5;124m\"\u001b[39m], encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     )\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# Set the custom prompt\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\utilities\\bash.py:17\u001b[0m, in \u001b[0;36m_lazy_import_pexpect\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Import pexpect only when needed.\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPersistent bash processes are not yet supported on Windows.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpexpect\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Persistent bash processes are not yet supported on Windows."
     ]
    }
   ],
   "source": [
    "from langchain.utilities.bash import BashProcess\n",
    "\n",
    "\n",
    "persistent_process = BashProcess(persistent=True)\n",
    "bash_chain = LLMBashChain.from_llm(llm, bash_process=persistent_process, verbose=True)\n",
    "\n",
    "text = \"List the current directory then move up a level.\"\n",
    "\n",
    "bash_chain.run(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the same command again and see that the state is maintained between calls\n",
    "bash_chain.run(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0924c3",
   "metadata": {},
   "source": [
    "## Router Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9487ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b5a68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41cd8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "894dcd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "659ab7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec5b0b",
   "metadata": {},
   "source": [
    "### LLMRouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "105d308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44c74193",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18083550",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, destination_chains=destination_chains, default_chain=default_chain, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0c158aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "Black body radiation is the thermal electromagnetic radiation emitted by a black body due to its temperature. A black body is an idealized physical body that absorbs all incident electromagnetic radiation, regardless of frequency or angle of incidence. It is a perfect absorber, but it is also a perfect emitter, meaning that it emits a characteristic spectrum of radiation that depends only on its temperature. This spectrum is known as black body radiation and is the source of the ultraviolet catastrophe.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"What is black body radiation?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d15e61e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'What is the first prime number greater than 40 such that one plus the prime number is divisible by 3?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "The answer is 43. One plus 43 (44) is divisible by 3.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"What is the first prime number greater than 40 such that one plus the prime number is divisible by 3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9813057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'What is the name of the type of cloud that rins'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The type of cloud that rains is called a cumulonimbus cloud. It's a type of thunderstorm cloud that is tall, dense, and vertically developed. It often produces heavy precipitation and strong winds.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"What is the name of the type of cloud that rins\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e76479",
   "metadata": {},
   "source": [
    "### EmbeddingRouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae6a6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.embedding_router import EmbeddingRouterChain\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52a4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_and_descriptions = [\n",
    "    (\"physics\", [\"for questions about physics\"]),\n",
    "    (\"math\", [\"for questions about math\"]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac037287",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"COHERE_API_KEY\"] =\"cohere api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b63f3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cohere\n",
      "  Downloading cohere-4.11.2-py3-none-any.whl (39 kB)\n",
      "Collecting importlib_metadata<7.0,>=6.0\n",
      "  Using cached importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from cohere) (2.2.1)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from cohere) (3.8.4)\n",
      "Requirement already satisfied: requests<3.0,>=2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from cohere) (2.30.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (3.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.0->cohere) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.0->cohere) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.0->cohere) (2023.5.7)\n",
      "Installing collected packages: importlib_metadata, cohere\n",
      "  Attempting uninstall: importlib_metadata\n",
      "    Found existing installation: importlib-metadata 4.11.3\n",
      "    Uninstalling importlib-metadata-4.11.3:\n",
      "      Successfully uninstalled importlib-metadata-4.11.3\n",
      "Successfully installed cohere-4.11.2 importlib_metadata-6.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6666af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = EmbeddingRouterChain.from_names_and_descriptions(\n",
    "    names_and_descriptions, Chroma, CohereEmbeddings(), routing_keys=[\"input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f234196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, destination_chains=destination_chains, default_chain=default_chain, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a5ca30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "Black body radiation is the type of electromagnetic radiation that is emitted from a black body in thermodynamic equilibrium. A black body is an idealized physical body that absorbs all incident electromagnetic radiation, regardless of frequency or angle of incidence. The emitted energy is a function of the temperature of the body, and is known as the Stefan-Boltzmann law.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"What is black body radiation?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "064e5cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'What is the first prime number greater than 40 such that one plus the prime number is divisible by 3'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "?\n",
      "\n",
      "The first prime number greater than 40 such that one plus the prime number is divisible by 3 is 43. To find this number, you can start by listing out the prime numbers greater than 40: 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97. Then, you can add 1 to each number to check if it is divisible by 3. The first number that is divisible by 3 is 43 + 1 = 44, so 43 is the answer.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"What is the first prime number greater than 40 such that one plus the prime number is divisible by 3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b642c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bebe78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61844d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a55dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d0cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0446ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ed4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8fbdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6b9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16c099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed012fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fed991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd053317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c779e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
